{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9855ba15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from playwright.sync_api import sync_playwright\n",
    "from playwright.async_api import async_playwright, expect, TimeoutError\n",
    "import json\n",
    "from pathlib import Path\n",
    "import time\n",
    "from datetime import date, timedelta\n",
    "import asyncio\n",
    "from urllib.parse import urljoin\n",
    "import os\n",
    "from urllib.parse import urlparse, parse_qs, unquote\n",
    "import re\n",
    "from pydoc import cli\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e407f5",
   "metadata": {},
   "source": [
    "# 1. Get list of links (Playwright)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d4649f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# login info \n",
    "user, pw = 'katrina.mullan@mso.umt.edu', 'wvp6rau6rqb_bwy1EYT!'\n",
    "url = 'https://pinnacle.azira.com/'\n",
    "\n",
    "\n",
    "async def start_browser(headless=False):\n",
    "    playwright = await async_playwright().start()\n",
    "\n",
    "    browser = await playwright.chromium.launch(headless=headless)\n",
    "\n",
    "    context = await browser.new_context(\n",
    "        geolocation={\"latitude\": 46.8721, \"longitude\": -113.9940},\n",
    "        permissions=[\"geolocation\"],\n",
    "    )\n",
    "\n",
    "    page = await context.new_page()\n",
    "\n",
    "    return {\n",
    "        \"playwright\": playwright,\n",
    "        \"browser\": browser,\n",
    "        \"context\": context,\n",
    "        \"page\": page,\n",
    "    }\n",
    "\n",
    "async def login(page, user, pw):\n",
    "    await page.goto(url) \n",
    "    await page.get_by_role(\"textbox\", name=\"Email Address\").fill(user)\n",
    "    await page.get_by_role(\"textbox\", name=\"Password\").fill(pw)\n",
    "    await page.get_by_role(\"button\", name=\"Log in\").click()\n",
    "\n",
    "    # wait for page load\n",
    "    await page.wait_for_url(\"**/home/feeds/datasets**\")\n",
    "    load_more = page.get_by_role(\"button\", name=\"Load More\")\n",
    "    await load_more.wait_for(state=\"visible\")\n",
    "\n",
    "# get links on a page\n",
    "async def get_links(page, restrict_state=None):\n",
    "    links = []      \n",
    "\n",
    "    rows = page.locator(\"table tr\")\n",
    "    row_count = await rows.count()\n",
    "\n",
    "    for i in range(row_count):\n",
    "        links_cell = rows.nth(i).locator(\"td:nth-child(4)\")\n",
    "\n",
    "        # skip empty cells\n",
    "        if await links_cell.count() == 0:\n",
    "            continue    \n",
    "\n",
    "        # get row metadata\n",
    "        job_id = await rows.nth(i).locator(\"td:nth-child(1)\").inner_text()   \n",
    "        job_name = await rows.nth(i).locator(\"td:nth-child(2)\").inner_text()\n",
    "\n",
    "        if restrict_state:\n",
    "            for name_item in job_name.split(\"_\")[::-1]:\n",
    "                if not name_item in ['a','b']:\n",
    "                    state = name_item\n",
    "                    break\n",
    "            if state not in restrict_state:\n",
    "                continue    \n",
    "\n",
    "        anchors = links_cell.locator(\"a\")\n",
    "        link_count = await anchors.count()\n",
    "        for j in range(link_count):\n",
    "            link = anchors.nth(j)\n",
    "            text = (await link.inner_text()).strip()   # \"Pin Dataset\" or \"Expanded Standard Dataset\"\n",
    "\n",
    "            if \"Pin Dataset\" in text or \"Expanded Standard\" in text:\n",
    "                text_link = await link.get_attribute(\"href\")\n",
    "                if text_link:\n",
    "                    links.append((job_id, job_name, text, text_link))\n",
    "\n",
    "    return links\n",
    "\n",
    "\n",
    "# filter for already downloaded files\n",
    "def filter_downloaded(all_links):\n",
    "\n",
    "    new_links = []\n",
    "\n",
    "    for a in all_links:\n",
    "        filename = filename_from_url(a[3])\n",
    "        if not Path(f\"azira_downloads/{filename}\").exists():\n",
    "            print(f\"adding {filename} to download list\")\n",
    "            new_links.append(a)\n",
    "\n",
    "    return new_links    \n",
    "\n",
    "def _safe(s: str) -> str:\n",
    "    return \"\".join(c if c.isalnum() or c in \"._- \" else \"_\" for c in s).strip()\n",
    "\n",
    "def filename_from_url(url):\n",
    "    qs = parse_qs(urlparse(url).query)\n",
    "    cd = qs.get(\"response-content-disposition\", [None])[0]\n",
    "    if not cd:\n",
    "        return None\n",
    "    cd = unquote(cd)  # attachment; filename=\"...\"\n",
    "    m = re.search(r'filename=\"?([^\"]+)\"?', cd)\n",
    "    return m.group(1) if m else None\n",
    "\n",
    "\n",
    "async def click_load_more_button(page):   \n",
    "    while True:\n",
    "        load_more = page.get_by_role(\"button\", name=\"Load More\")\n",
    "\n",
    "        if await load_more.is_visible():\n",
    "            await load_more.click()\n",
    "        else:\n",
    "            print(\"end of the line\")\n",
    "            break\n",
    "        # Wait for new rows to load before next iteration\n",
    "        await page.wait_for_timeout(1000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae63ec7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end of the line\n"
     ]
    }
   ],
   "source": [
    "# login \n",
    "browser_handle = await start_browser(headless=False)\n",
    "page = browser_handle[\"page\"]\n",
    "await login(page, user, pw)\n",
    "\n",
    "await click_load_more_button(page)\n",
    "\n",
    "my_states = ['Colorado', 'Oklahoma', 'Utah', 'California', 'Nevada', \"New\", \"Arizona\", \"North\"]\n",
    "all_links = await get_links(page, my_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d0a70e",
   "metadata": {},
   "source": [
    "## 2. Write urls.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5676b7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click \"Load More\" until the button is no longer visible\n",
    "with open(\"urls.txt\", \"w\") as f:\n",
    "    for item in all_links:\n",
    "        url = item[3]\n",
    "        f.write(f\"{url}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0d15b3",
   "metadata": {},
   "source": [
    "## 3. Tranfser urls.txt to hellgate (scp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e54e4370",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SSH_AGENT_PID not set, cannot kill agent\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['scp', '-i', '/home/vince/.ssh/um_vpn', 'urls.txt', 'vc149353@um:/mnt/beegfs/hellgate/home/vc149353/osm_fitness/Azira/urls.txt'], returncode=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "local_file = \"urls.txt\"\n",
    "remote =  \"vc149353@um:/mnt/beegfs/hellgate/home/vc149353/osm_fitness/Azira/urls.txt\"\n",
    "\n",
    "subprocess.run(\n",
    "    [\n",
    "        \"scp\",\n",
    "        \"-i\", \"/home/vince/.ssh/um_vpn\",\n",
    "        f\"{local_file}\",\n",
    "        f\"{remote}\",\n",
    "    ],\n",
    "    check=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
