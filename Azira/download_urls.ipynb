{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ce8dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import threading\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from urllib.parse import urlparse, parse_qs, unquote\n",
    "import re\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af8671f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ---------------- config ----------------\n",
    "URLS_FILE = \"/mnt/beegfs/hellgate/home/vc149353/osm_fitness/Azira/urls.txt\"\n",
    "OUT_DIR = \"/mnt/beegfs/hellgate/home/vc149353/azira_downloads\"\n",
    "MAX_WORKERS = 10\n",
    "TIMEOUT = 60          # seconds per request\n",
    "RETRIES = 5\n",
    "CHUNK_SIZE = 1024 * 1024  # 1 MB\n",
    "# ----------------------------------------\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "lock = threading.Lock()\n",
    "\n",
    "\n",
    "def filename_from_url(url):\n",
    "    qs = parse_qs(urlparse(url).query)\n",
    "    cd = qs.get(\"response-content-disposition\", [None])[0]\n",
    "    if not cd:\n",
    "        return None\n",
    "    cd = unquote(cd)  # attachment; filename=\"...\"\n",
    "    m = re.search(r'filename=\"?([^\"]+)\"?', cd)\n",
    "    return m.group(1) if m else None\n",
    "\n",
    "\n",
    "def download_one(url: str):\n",
    "    name = filename_from_url(url)\n",
    "    out_path = os.path.join(OUT_DIR, name)\n",
    "\n",
    "    if os.path.exists(out_path):\n",
    "        with lock:\n",
    "            print(f\"[skip] {name}\")\n",
    "        return\n",
    "\n",
    "    for attempt in range(1, RETRIES + 1):\n",
    "        try:\n",
    "            with requests.get(\n",
    "                url,\n",
    "                stream=True,\n",
    "                timeout=TIMEOUT,\n",
    "                allow_redirects=True,\n",
    "            ) as r:\n",
    "                r.raise_for_status()\n",
    "\n",
    "                # Honor Content-Disposition if present\n",
    "                cd = r.headers.get(\"Content-Disposition\", \"\")\n",
    "                if \"filename=\" in cd:\n",
    "                    fname = cd.split(\"filename=\")[-1].strip(\"\\\"'\")\n",
    "                    out_path = os.path.join(OUT_DIR, fname)\n",
    "                    if os.path.exists(out_path):\n",
    "                        with lock:\n",
    "                            print(f\"[skip] {fname}\")\n",
    "                        return\n",
    "\n",
    "                tmp = out_path + \".part\"\n",
    "                with open(tmp, \"wb\") as f:\n",
    "                    for chunk in r.iter_content(chunk_size=CHUNK_SIZE):\n",
    "                        if chunk:\n",
    "                            f.write(chunk)\n",
    "\n",
    "                os.replace(tmp, out_path)\n",
    "\n",
    "                with lock:\n",
    "                    print(f\"[ok]   {os.path.basename(out_path)}\")\n",
    "                return\n",
    "\n",
    "        except Exception as e:\n",
    "            if attempt == RETRIES:\n",
    "                with lock:\n",
    "                    print(f\"[FAIL] {name}: {e}\")\n",
    "            else:\n",
    "                time.sleep(2 ** attempt)\n",
    "\n",
    "\n",
    "def main():\n",
    "    if not os.path.exists(URLS_FILE):\n",
    "        print(f\"missing {URLS_FILE}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    with open(URLS_FILE) as f:\n",
    "        urls = [l.strip() for l in f if l.strip()]\n",
    "\n",
    "    urls = urls[:10]\n",
    "\n",
    "    if not urls:\n",
    "        print(\"no URLs found\")\n",
    "        return\n",
    "\n",
    "    print(f\"Downloading {len(urls)} files with {MAX_WORKERS} threads\")\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:\n",
    "        futures = [ex.submit(download_one, url) for url in urls]\n",
    "        for _ in as_completed(futures):\n",
    "            pass\n",
    "\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "    #main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ba9f6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 10 files with 10 threads\n",
      "[ok]   10057375_Greenville_North_expanded_cel_cdl_report.zip\n",
      "[ok]   10057376_Charlotte_4_b_North_pin_report.tsv.gz\n",
      "[ok]   10057374_Wilmington_North_expanded_cel_cdl_report.zip\n",
      "[ok]   10057376_Charlotte_4_b_North_expanded_cel_cdl_report.zip\n",
      "[ok]   10057377_Charlotte_4_a_North_expanded_cel_cdl_report.zip\n",
      "[ok]   10057378_Belmont_b_North_expanded_cel_cdl_report.zip\n",
      "[ok]   10057377_Charlotte_4_a_North_pin_report.tsv.gz\n",
      "[ok]   10057378_Belmont_b_North_pin_report.zip\n",
      "[ok]   10057375_Greenville_North_pin_report.tsv.gz\n",
      "[ok]   10057385_Greensboro_2_North_pin_report.tsv.gz\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
